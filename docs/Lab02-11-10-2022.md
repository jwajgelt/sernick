# Lab 02: Implementacja Lexera
Lexer to część kompilatora odpowiedzialna za rozdzielanie kodu źródłowego na Tokeny.
Na wykładzie poznaliśmy dwa podejścia do implementacji  Lexera:

1. NFA -> DFA -> Minimalizacja
2. Pochodne Brzozowskiego

**Decyzja:** Implementujemy Lexer wykorzystując pochodne Brzozowskiego.

## Regexy i pochodne
Jak będziemy opisywać regexy?

### Regex:
* *atom*: pojedyncza litera; Konstrukcja: `Atom(atom: Char)`
  
* *union*: Suma mnogościowa; Rozważyliśmy konstrukcje:
  - binarną: `Union(a: Regex, b: Regex)`
  - N-arną: `Union(...Regex children)` (dopuszczamy N=0)

  **Decyzja:** Wybraliśmy N-arną `Union(children: Enumerable<Regex>)` bo wtedy nie musimy pisać pustego języka i mamy trochę łatwiejszą normalizacje.

* *konkatenacja*: łączenie zgodnie z kolejnością; Podobnie jak w union wybraliśmy N-arną konstrukcję: `Concat(children: Enumerable<Regex>)`.
  
* *star*: gwiazda Kleene'ego; Konstrukcja `Start(child: Regex)`

Najłatwiej to ująć klasą bazową (abstrakcyjną?) z klasami pochodnymi czyli
Base `class Regex` oraz `AtomRegex, UnionRegex, ConcatRegex, StarRegex`


##### Co jest do zrobienia?
(**AI** - action item)

* **AI [DB]** - Implementacja normalizacji regexów w factory methods (nie bezpośrednio w konstruktorach)

* **AI [SS]** Implementacja `IEquatable<Regex>` w klasach `Regex` (naturalny sposób w C# żeby powiedzieć że coś jest porównywalne)
  Zakładamy, że powstałe regexy zawsze są znormalizowane więc porównujemy je strukturalnie.

* **AI [PK]** Metoda `containsEpsilon(): bool` -- abstrakcyjna w Regex i do zaimplementowania w podklasach.

* **AI [PK]** Metoda `derivative(atom: Char): Regex` -- abstrakcyjna w Regex i do zaimplementowania w podklasach.



### Automat

#### Interfejs IDfa:
* Stan startowy: jak to zrobić?
  1. Trzymamy stan za pomocą Int
  2. `IDfaState` (interfejs) -- wada: trzeba rzutować
  3. `IDfa<TState>` -- symulacja za pomocą generyków, wada: boilerplate
   
  **Decyzja:** Wybraliśmy opcje 3 -- automat podaje jako generyk typ stanu
* `IsAccepting(state): bool`
* `IsDead(state): bool`
* `Transition(TState, Char): TState`
* każdy automat musi mieć stan martwy (zwracamy go z transition() jeśli nie ma przejścia)

* **AI [KZ]** - Implementacja klasy `RegexDfa: IDfa`

### Lexer
Na wejściu dostaje ciąg znaków, a na wyjściu wypluwa ciąg tokenów.

Interfejs `ILexer<TCategory, TState>`
* `Process(...): IEnumerable<Token<TCategory>>`

Klasa `Lexer`
* Konstruktor: `Lexer(ReadonlyDictionary<TCategory, IDfa<TState>>)`
* **AI [JW]** - Implementacja klasy `Lexer`

### Token
Token to słowa kluczowe | identyfikatory | liczby | nawias | itd.

Klasa `Token<TCategory>`:
* `Text: string`
* `Category: TCategory`
* `Start: ILocation`
* `End: ILocation`

Interfejs `ILocation`
* `ToString(): String` - zwraca opis dla użytkownika

Interfejs `IInput : IEnumerator<Char>`
* `CurrentLocation: ILocation { get; }`
* `MoveTo(ILocation): void;`
* **AI [AK]** - Implementacja klasy `StringInput: IInput`


### Gramatyka

Faktyczne kategorie tokenow w języku.
* **AI [WR]** - Przygotować regexy dla tokenów w SernickLang
* **AI [BB]** - Zaimplementować parser String to Regex, który ułatwi definiowanie regexów
